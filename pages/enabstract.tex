% 英文摘要

In the areas of location services and scene perception, as an effective mechanism to solve problems, multi-sensor fusion can make full use of the complementary attributes of diverse sensors to provide better and more reliable services in complex environments. For a multi-sensor system, the correct calibration of spatio-temporal parameters is the prerequisite to ensure fusion algorithms work properly, and the calibration accuracy of relevant parameters directly affects the performance of algorithms. To this end, we propose a target-free LiDAR/Camera/IMU spatio-temporal calibration method based on continuous-time estimation. This method estimates parameters using constraints constructed by environmental features without relying on targets or prior knowledge and considers the calibration of both spatial and temporal parameters of the multi-sensor platform. In particularly, this method uses B-spline curves to model the pose trajectory based on continuous time theory, which tightly incorporates the estimation of the temporal parameters into the factor graph and yields a higher calibration accuracy compared to the discrete-time estimation method in highly dynamic scenarios.Subsequently, we performed a theoretical analysis and experimental verification of the system's observability under different forms of motion based on the Lie derivative, and proved that the whole system is completely observable under random motion. Simulation and real-world experiments are carried out to verify the feasibility of the proposed method and evaluate its performance, and the results demonstrate that our method can achieve high calibration accuracy of spatio-temporal parameters with the guarantee of system consistency.